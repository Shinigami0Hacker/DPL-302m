{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install autocorrect"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKMNYnxd5lFb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698150189257,
     "user_tz": -420,
     "elapsed": 6785,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "9fbd0ec4-492f-4cea-b1d4-8e92873661ea"
   },
   "id": "HKMNYnxd5lFb",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m622.8/622.8 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=06118e6bdab2bd2a4b895bc446c254ae280752cfa392221c10ad965bcd77c6ed\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2023-10-25T08:07:17.158181400Z",
     "start_time": "2023-10-25T08:07:10.821769200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "drive_url = \"/content/drive/MyDrive/LSTM-GRU-data/\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4XuVLrni7dZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698150220033,
     "user_tz": -420,
     "elapsed": 28565,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "f8fa6cb1-096c-44af-d728-4374756b5292"
   },
   "id": "p4XuVLrni7dZ",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_target = \"Dataset/\"\n",
    "img_targer = \"Img/\"\n",
    "model_checkpoint_target = \"Model_checkpoint/\"\n",
    "preprocessed_target = \"Preprocessed/\"\n",
    "pretrained_target = \"Pretrained/\""
   ],
   "metadata": {
    "id": "BNBYQBwSjIef",
    "ExecuteTime": {
     "end_time": "2023-10-25T08:07:19.124053Z",
     "start_time": "2023-10-25T08:07:19.102295100Z"
    }
   },
   "id": "BNBYQBwSjIef",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "spell = Speller(lang='en')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "removal_positive = ['but', \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\",\n",
    "                    \"mightn't\", \"mustn't\", \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"won't\", \"wouldn't\"]\n",
    "stop_words.difference_update(removal_positive)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e09b035eb42a64ad",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698150221035,
     "user_tz": -420,
     "elapsed": 1005,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "3cc3d498-0286-442f-fb32-61df16905971",
    "ExecuteTime": {
     "end_time": "2023-10-25T08:07:23.198098100Z",
     "start_time": "2023-10-25T08:07:22.425107600Z"
    }
   },
   "id": "e09b035eb42a64ad"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a',\n 'about',\n 'above',\n 'after',\n 'again',\n 'against',\n 'ain',\n 'all',\n 'am',\n 'an',\n 'and',\n 'any',\n 'are',\n 'aren',\n 'as',\n 'at',\n 'be',\n 'because',\n 'been',\n 'before',\n 'being',\n 'below',\n 'between',\n 'both',\n 'by',\n 'can',\n 'couldn',\n 'd',\n 'did',\n 'didn',\n 'do',\n 'does',\n 'doesn',\n 'doing',\n 'don',\n 'down',\n 'during',\n 'each',\n 'few',\n 'for',\n 'from',\n 'further',\n 'had',\n 'hadn',\n 'has',\n 'hasn',\n 'have',\n 'haven',\n 'having',\n 'he',\n 'her',\n 'here',\n 'hers',\n 'herself',\n 'him',\n 'himself',\n 'his',\n 'how',\n 'i',\n 'if',\n 'in',\n 'into',\n 'is',\n 'isn',\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'just',\n 'll',\n 'm',\n 'ma',\n 'me',\n 'mightn',\n 'more',\n 'most',\n 'mustn',\n 'my',\n 'myself',\n 'needn',\n 'no',\n 'nor',\n 'not',\n 'now',\n 'o',\n 'of',\n 'off',\n 'on',\n 'once',\n 'only',\n 'or',\n 'other',\n 'our',\n 'ours',\n 'ourselves',\n 'out',\n 'over',\n 'own',\n 're',\n 's',\n 'same',\n 'shan',\n 'she',\n \"she's\",\n 'should',\n \"should've\",\n 'shouldn',\n 'so',\n 'some',\n 'such',\n 't',\n 'than',\n 'that',\n \"that'll\",\n 'the',\n 'their',\n 'theirs',\n 'them',\n 'themselves',\n 'then',\n 'there',\n 'these',\n 'they',\n 'this',\n 'those',\n 'through',\n 'to',\n 'too',\n 'under',\n 'until',\n 'up',\n 've',\n 'very',\n 'was',\n 'wasn',\n 'we',\n 'were',\n 'weren',\n \"weren't\",\n 'what',\n 'when',\n 'where',\n 'which',\n 'while',\n 'who',\n 'whom',\n 'why',\n 'will',\n 'with',\n 'won',\n 'wouldn',\n 'y',\n 'you',\n \"you'd\",\n \"you'll\",\n \"you're\",\n \"you've\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:07:29.998672400Z",
     "start_time": "2023-10-25T08:07:29.989313600Z"
    }
   },
   "id": "7b065da71ba7db6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Import data\n",
    "2. Define column to be cleaned\n",
    "3. clean each row of that column\n",
    "4. make it as column after cleaned -> to csv\n",
    "5. from cleaned csv to column to augment\n",
    "6. copy a subset to be augmented\n",
    "7. augment that subset -> to csv"
   ],
   "metadata": {
    "collapsed": false,
    "id": "5a8a7a299ca86dfc"
   },
   "id": "5a8a7a299ca86dfc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 & 2"
   ],
   "metadata": {
    "collapsed": false,
    "id": "f3fc9dce1d847f94"
   },
   "id": "f3fc9dce1d847f94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-17-8023912c660c>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'].replace({'positive': 1, 'negative': 0}, inplace=True)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    218838\n",
       "1    165154\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data = pd.read_csv(drive_url+dataset_target+\"text_emotion.csv\")\n",
    "# data = data.head(5)\n",
    "columns = [\"id\", \"text\", \"label\"]\n",
    "data.columns = columns\n",
    "\n",
    "# truncate class: surprise\n",
    "data = data[data[\"label\"] != \"surprise\"]\n",
    "\n",
    "# truncate duplicate by A\n",
    "data = data.drop_duplicates(subset=['text'])\n",
    "\n",
    "# convert label by class: {pos:1, neg:0}\n",
    "data['label'].replace({'positive': 1, 'negative': 0}, inplace=True)\n",
    "data[\"label\"].value_counts()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T03:29:53.250347Z",
     "start_time": "2023-10-24T03:29:52.452300300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8171feeabe9889c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132212505,
     "user_tz": -420,
     "elapsed": 1765,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "5cd05196-8b55-4ee7-f5e1-fbba395c6d98"
   },
   "id": "c8171feeabe9889c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3"
   ],
   "metadata": {
    "collapsed": false,
    "id": "af4f06e5fbac709e"
   },
   "id": "af4f06e5fbac709e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'don feel good today'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def reduce_lengthening(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Reduce consecutive character lengthening in the input text.\n",
    "\n",
    "    This function identifies consecutive character lengthening (e.g., \"sooo\" or \"coooool\") in the text and replaces them with double characters (e.g., \"soo\" or \"cool\").\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input text containing potential character lengthening.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with consecutive character lengthening reduced.\n",
    "\n",
    "    Example:\n",
    "        >>> reduced_text = reduce_lengthening(\"sooo good!\")\n",
    "        >>> print(reduced_text)\n",
    "        \"soo good!\"\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "\n",
    "def text_preprocess(doc: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform comprehensive text preprocessing on the input document.\n",
    "\n",
    "    This function performs several text preprocessing steps, including lowercase conversion, removal of hashtags, mentions, links, numbers, and more.\n",
    "    It also tokenizes the text, reduces word lengthening, corrects spelling, lemmatizes words, and removes short words.\n",
    "\n",
    "    Parameters:\n",
    "        doc (str): The input document to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "\n",
    "    Example:\n",
    "        >>> preprocessed_text = text_preprocess(\"I love this product! It's amazing!!!\")\n",
    "        >>> print(preprocessed_text)\n",
    "        \"love product amazing\"\n",
    "    \"\"\"\n",
    "    #Lowercasing all the letters\n",
    "    temp = doc.lower()\n",
    "    #Removing hashtags and mentions\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\", \"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\", \"\", temp)\n",
    "    #Removing links\n",
    "    temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp)\n",
    "    #removing numbers\n",
    "    temp = re.sub(\"[0-9]\", \"\", temp)\n",
    "    #Removing '\n",
    "    temp = re.sub(\"'\", \" \", temp)\n",
    "\n",
    "    #Tokenization\n",
    "    temp = word_tokenize(temp)\n",
    "    #Fixing Word Lengthening\n",
    "    temp = [reduce_lengthening(w) for w in temp]\n",
    "    #spell corrector\n",
    "    temp = [spell(w) for w in temp]\n",
    "    #stem\n",
    "    temp = [lemmatizer.lemmatize(w) for w in temp]\n",
    "    #Removing short words\n",
    "    temp = [w for w in temp if len(w) > 2]\n",
    "\n",
    "    temp = \" \".join(w for w in temp)\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "examples_test_cleaning_text = \"I don't feel good today\"\n",
    "\n",
    "text_preprocess(examples_test_cleaning_text)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T04:08:11.410015300Z",
     "start_time": "2023-10-24T04:08:11.406927900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "92989f0720ae2aea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698121241319,
     "user_tz": -420,
     "elapsed": 1345,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "c12735f6-6eda-4153-c7cb-0f3afcbed1c0"
   },
   "id": "92989f0720ae2aea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned_text = [text_preprocess(sent) for sent in data['text']]"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T04:09:35.135382100Z",
     "start_time": "2023-10-24T04:09:24.206112500Z"
    },
    "id": "77814bfcfec7513c"
   },
   "id": "77814bfcfec7513c"
  },
  {
   "cell_type": "code",
   "source": [
    "np.save(drive_url+preprocessed_target+\"cleaned_text.npy\",cleaned_text)"
   ],
   "metadata": {
    "id": "9hh7mOQnkW9S"
   },
   "id": "9hh7mOQnkW9S",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['text'] = cleaned_text"
   ],
   "metadata": {
    "id": "7105aaa99326f0cb"
   },
   "id": "7105aaa99326f0cb"
  },
  {
   "cell_type": "code",
   "source": [
    "len(cleaned_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g42DrPp9gk9P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698131585510,
     "user_tz": -420,
     "elapsed": 6,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "6672549f-be76-46b0-e93a-400ab9f85b20"
   },
   "id": "g42DrPp9gk9P",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "383992"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4"
   ],
   "metadata": {
    "collapsed": false,
    "id": "bf5d29985c1b8984"
   },
   "id": "bf5d29985c1b8984"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.to_csv(drive_url+dataset_target+\"cleaned_text_emotion.csv\")"
   ],
   "metadata": {
    "id": "637d330fe179732"
   },
   "id": "637d330fe179732"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5"
   ],
   "metadata": {
    "collapsed": false,
    "id": "2242d9336d181dd7"
   },
   "id": "2242d9336d181dd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    54501\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "positive_data = data[data['label']==1]\n",
    "negative_data = data[data['label']==0]\n",
    "positive_data_sample = positive_data.sample(frac=0.33,random_state=17)\n",
    "positive_data_sample['label'].value_counts()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T03:29:53.315351600Z",
     "start_time": "2023-10-24T03:29:53.250347Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef1c294540652c8b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132405297,
     "user_tz": -420,
     "elapsed": 379,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "346b539c-728f-4b2e-e53d-9e2084b5a543"
   },
   "id": "ef1c294540652c8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    165154\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "positive_data['label'].value_counts()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T03:29:53.315351600Z",
     "start_time": "2023-10-24T03:29:53.285288400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91d731ee27380cb1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132409697,
     "user_tz": -420,
     "elapsed": 903,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "0ffd26aa-3ca6-4298-e97c-838415563687"
   },
   "id": "91d731ee27380cb1"
  },
  {
   "cell_type": "code",
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "positive_data['text'].head(5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTBnixdGlE3_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132536299,
     "user_tz": -420,
     "elapsed": 337,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "e4599237-1611-4819-f037-fcb4341d6d26"
   },
   "id": "KTBnixdGlE3_",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2    ive probably mentioned this before but really ...\n",
       "4    believe that much more sensitive other people ...\n",
       "5    find myself frustrated with christian because ...\n",
       "6    one those people who feel like going the gym o...\n",
       "7    feel especially pleased about this this been l...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    218838\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "negative_data['label'].value_counts()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T03:29:53.315351600Z",
     "start_time": "2023-10-24T03:29:53.296433700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d08422f7baeebec",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132410415,
     "user_tz": -420,
     "elapsed": 2,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "5dce3828-1bf1-412c-8c0f-30a64a1133b5"
   },
   "id": "9d08422f7baeebec"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "9372f9e49ba685c4"
   },
   "id": "9372f9e49ba685c4"
  },
  {
   "cell_type": "code",
   "source": [
    "negative_data['text'].head(5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsoX0KsKlNpR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698132539618,
     "user_tz": -420,
     "elapsed": 492,
     "user": {
      "displayName": "Project DPL",
      "userId": "03141633761799123373"
     }
    },
    "outputId": "2a395223-5e03-44cc-e45b-3fce83905584"
   },
   "id": "GsoX0KsKlNpR",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     feel awful about too because job get him posit...\n",
       "1                                      alone feel awful\n",
       "3                       feeling little low few day back\n",
       "9               feel enraged but helpless the same time\n",
       "10                          said feeling bit rebellious\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
